{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-2 (Chinese) Placeholder Fine-Tuning Pipeline\n",
        "\n",
        "This notebook runs the repeatable dev-only pipeline script: `scripts/run_gpt2_pipeline.py`.\n",
        "\n",
        "What it does:\n",
        "- Builds a local JSONL corpus from multiple sources (masked-pair datasets + token NER datasets)\n",
        "- Canonicalizes placeholder tokens (e.g. `<LASTNAME_1>` â†’ `<NAME>`)\n",
        "- Fine-tunes a local GPT-2 style model on the placeholder corpus\n",
        "- Copies the final model into `/mnt/c/ai_models/llm/edge_deid/<run_slug>/`\n",
        "\n",
        "Notes:\n",
        "- This is **dev-only** and requires explicit network enablement on the first run.\n",
        "- The runtime de-identification pipeline remains local-only and does not depend on GPT-2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# AI_WAREHOUSE 3.0 cache layout (avoid $HOME/.cache)\n",
        "os.environ.setdefault('EDGE_DEID_CACHE_HOME', '/mnt/c/ai_cache')\n",
        "os.environ.setdefault('EDGE_DEID_MODELS_HOME', '/mnt/c/ai_models')\n",
        "os.environ.setdefault('EDGE_DEID_DATA_HOME', '/mnt/data')\n",
        "\n",
        "os.environ.setdefault('HF_HOME', '/mnt/c/ai_cache/huggingface')\n",
        "os.environ.setdefault('TRANSFORMERS_CACHE', os.environ['HF_HOME'])\n",
        "os.environ.setdefault('TORCH_HOME', '/mnt/c/ai_cache/torch')\n",
        "os.environ.setdefault('XDG_CACHE_HOME', '/mnt/c/ai_cache')\n",
        "os.environ.setdefault('PIP_CACHE_DIR', '/mnt/c/ai_cache/pip')\n",
        "\n",
        "for key in ('HF_HOME', 'TORCH_HOME', 'XDG_CACHE_HOME', 'PIP_CACHE_DIR'):\n",
        "    Path(os.environ[key]).expanduser().mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Smoke run (downloads base model + datasets on first run).\n",
        "!PYTHONPATH=src python scripts/run_gpt2_pipeline.py \\\n",
        "  --config configs/training/gpt2_zh_placeholder_smoke.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "report_path = Path('/mnt/data/training/logs/edge_deid/gpt2-zh-placeholder-smoke/report.json')\n",
        "report = json.loads(report_path.read_text(encoding='utf-8'))\n",
        "\n",
        "print('Corpus:', report.get('corpus_jsonl'))\n",
        "print('Training output:', report.get('training_output_dir'))\n",
        "print('Models output:', report.get('models_output_dir'))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

