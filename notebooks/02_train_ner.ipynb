{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLlppiXwWeObV3UFV/C0TI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Justin21523/edge-deid-studio/blob/feature%2Ftrain-ner-notebook/notebooks/02_train_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ·ï¸ NER å¾®èª¿ç¤ºç¯„ï¼ˆ02_train_ner.ipynbï¼‰\n",
        "\n",
        "> æœ¬ç­†è¨˜æœ¬ç¤ºç¯„å¦‚ä½•ä¸‹è¼‰è³‡æ–™ã€Tokenizeã€å°é½Šæ¨™ç±¤ã€ä»¥ Trainer é€²è¡Œ NER æ¨¡å‹å¾®èª¿ï¼Œä¸¦æŠŠçµæœå„²å­˜åˆ° `models/ner/v1.0`ã€‚  \n",
        "> **æ³¨æ„**ï¼šå…ˆåœ¨ CPU ç’°å¢ƒä¸‹ dry runï¼Œç¢ºèªç„¡èª¤å¾Œå†åˆ‡åˆ° GPU Runtime ä¸€éµåŸ·è¡Œæ•´å€‹æµç¨‹ã€‚\n",
        "\n",
        "## 1ï¸âƒ£ ç’°å¢ƒæº–å‚™"
      ],
      "metadata": {
        "id": "xPoalFDO88nR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EuLYbuL7c0I"
      },
      "outputs": [],
      "source": [
        "# 1.1 å®‰è£ä¾è³´ï¼ˆåªéœ€è·‘ä¸€æ¬¡ï¼‰\n",
        "!pip install -q transformers datasets accelerate\n",
        "\n",
        "# 1.2 æ›è¼‰ Google Drive ä¸¦è¨­å®š HF å¿«å–\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.environ['HF_HOME'] = '/content/drive/MyDrive/hf_cache'\n",
        "os.environ['TRANSFORMERS_CACHE'] = '/content/drive/MyDrive/hf_cache/transformers'\n",
        "os.makedirs(os.environ['TRANSFORMERS_CACHE'], exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Hugging Face ç™»å…¥ï¼ˆç¬¬ä¸€æ¬¡ runtime å¿…è·‘ï¼‰\n",
        "from huggingface_hub import login\n",
        "from getpass import getpass\n",
        "hf_token = getpass(\"è«‹è²¼ä¸Šä½ çš„ Hugging Face tokenï¼š\")\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "id": "ntvKoFKa9ESN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4 æª¢æŸ¥ GPUï¼ˆåˆ‡åˆ° GPU Runtime å†è·‘ï¼‰\n",
        "import torch\n",
        "print(\"GPU available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "7cJz7Kh29HMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2ï¸âƒ£ è¼‰å…¥å¥—ä»¶èˆ‡è³‡æ–™é›†\n"
      ],
      "metadata": {
        "id": "q25Z2ymj9KaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "# 2.1 ä¸‹è¼‰ Conll2003 NER è³‡æ–™é›†\n",
        "raw_datasets = load_dataset(\"conll2003\")\n",
        "label_list   = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
        "num_labels   = len(label_list)\n",
        "print(\"Label åˆ—è¡¨ï¼š\", label_list)\n"
      ],
      "metadata": {
        "id": "7lHViPiW9MJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3ï¸âƒ£ Tokenizer èˆ‡ Model åˆå§‹åŒ–\n"
      ],
      "metadata": {
        "id": "58l_IodJ9Oe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"bert-base-cased\"\n",
        "tokenizer        = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model            = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "ilxh9vKh9P5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 å®šç¾©å°é½Šå‡½å¼\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "    all_labels     = examples[\"ner_tags\"]\n",
        "    aligned_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids          = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids         = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(labels[word_idx])\n",
        "            else:\n",
        "                label_ids.append(labels[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        aligned_labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# 4.2 map æ•´å€‹ dataset\n",
        "label_all_tokens   = False\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names\n",
        ")\n"
      ],
      "metadata": {
        "id": "4nyVyg079RXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5ï¸âƒ£ DataCollator èˆ‡ Trainer è¨­å®š\n"
      ],
      "metadata": {
        "id": "dwVTzpjl9Vg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 å‹•æ…‹ padding\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "# 5.2 è¨“ç·´åƒæ•¸\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"models/ner/v1.0\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "# 5.3 åˆå§‹åŒ– Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "hYh8vg7V9XGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6ï¸âƒ£ é–‹å§‹è¨“ç·´ï¼ˆå¾…åˆ‡åˆ° GPU Runtime å†åŸ·è¡Œï¼‰\n"
      ],
      "metadata": {
        "id": "FnLq8Vfk9Y3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train()ã€trainer.save_model() éƒ½æœƒæŠŠçµæœå­˜åˆ° models/ner/v1.0\n",
        "# åœ¨ CPU ç’°å¢ƒä¸‹å¯ä»¥å…ˆè¨»è§£æ‰ï¼ŒGPU ä¸€æ¬¡è·‘å®Œï¼š\n",
        "# trainer.train()\n",
        "# trainer.save_model()"
      ],
      "metadata": {
        "id": "rCkXrkVh9bmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ğŸ“Œ æ¥ä¸‹ä¾†çš„ Notebook è¦åŠƒ\n",
        "\n",
        "- **02_train_ner.ipynb**ï¼šConll2003 NER å¾®èª¿ç¤ºç¯„  \n",
        "- **03_finetune_gpt2.ipynb**ï¼šGPT-2 è‡ªå›æ­¸å¾®èª¿  \n",
        "- **04_inference.ipynb**ï¼šè¼‰å…¥å¾®èª¿å¾Œæ¨¡å‹åšæ¨ç†å±•ç¤º  \n",
        "- **05_export_onnx.ipynb**ï¼šå°‡å¾®èª¿å¾Œæ¨¡å‹è½‰ ONNXï¼edge_models  \n",
        "- **06_evaluate.ipynb**ï¼šæ¨¡å‹è©•ä¼°èˆ‡æŒ‡æ¨™è¦–è¦ºåŒ–\n",
        "\n",
        "æ‰€æœ‰ notebooks éƒ½æ”¾åœ¨ `notebooks/`ï¼Œæ¯å€‹åŠ ä¸Š badge â†’ Colab â†’ Save to GitHub â†’ åŒæ­¥åˆ° `notebooks/` è³‡æ–™å¤¾åº•ä¸‹ã€‚\n"
      ],
      "metadata": {
        "id": "UHtZoYb09gdL"
      }
    }
  ]
}