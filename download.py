from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "ckiplab/gpt2-base-chinese"
save_path = "./models/gpt2_zh"

print("ğŸš€ é–‹å§‹ä¸‹è¼‰æ¨¡å‹...", flush=True)
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, use_safetensors=True)
print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼Œæº–å‚™å„²å­˜...", flush=True)

tokenizer.save_pretrained(save_path)
model.save_pretrained(save_path)

print(f"ğŸ“¦ å·²æˆåŠŸå„²å­˜ GPT2 æ¨¡å‹åˆ°ï¼š{save_path}", flush=True)
